{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import datetime\n",
    "\n",
    "#library for representing the graphs\n",
    "import networkx as nx\n",
    "\n",
    "#library for Bellman Ford Algorithm\n",
    "import bellmanford as bf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifying Price Data\n",
    "<font color=#333333>I define a path where are stored all the datasets.</font>\n",
    "<font color=#333333>The command _os.listdir_ makes a list of all the files found in the directory</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_FILES = \"/home/pfl/Ironhack/project_Searching_for_Arbitrage_Opportunities_in_the_FX_Market_on_the_paper/datasets_csv\"\n",
    "filescsv = os.listdir(PATH_TO_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Xasmus.17302.PERIOD_M1.EURNZDmicro.csv',\n",
       " 'Xasmus.23925.PERIOD_M1.USDMXNmicro.csv',\n",
       " 'Xasmus.25659.PERIOD_M1.AUDCADmicro.csv',\n",
       " 'Xasmus.27030.PERIOD_M1.CADJPYmicro.csv',\n",
       " 'Xasmus.1343.PERIOD_M1.AUDCHFmicro.csv',\n",
       " 'Xasmus.9677.PERIOD_M1.USDSGDmicro.csv',\n",
       " 'Xasmus.2711.PERIOD_M1.EURGBPmicro.csv',\n",
       " 'Xasmus.13341.PERIOD_M1.GBPCADmicro.csv',\n",
       " 'Xasmus.27552.PERIOD_M1.NZDCADmicro.csv',\n",
       " 'Xasmus.3830.PERIOD_M1.GBPNOKmicro.csv',\n",
       " 'Xasmus.2386.PERIOD_M1.USDCADmicro.csv',\n",
       " 'Xasmus.2367.PERIOD_M1.EURNOKmicro.csv',\n",
       " 'Xasmus.2004.PERIOD_M1.GBPSGDmicro.csv',\n",
       " 'Xasmus.18640.PERIOD_M1.GBPDKKmicro.csv',\n",
       " 'Xasmus.15607.PERIOD_M1.GBPNZDmicro.csv',\n",
       " 'Xasmus.2091.PERIOD_M1.EURSGDmicro.csv',\n",
       " 'Xasmus.29230.PERIOD_M1.GBPCHFmicro.csv',\n",
       " 'Xasmus.6999.PERIOD_M1.SGDJPYmicro.csv',\n",
       " 'Xasmus.10086.PERIOD_M1.CADCHFmicro.csv',\n",
       " 'Xasmus.13730.PERIOD_M1.EURAUDmicro.csv',\n",
       " 'Xasmus.11037.PERIOD_M1.AUDJPYmicro.csv',\n",
       " 'Xasmus.2309.PERIOD_M1.NZDJPYmicro.csv',\n",
       " 'Xasmus.2834.PERIOD_M1.USDHUFmicro.csv',\n",
       " 'Xasmus.18723.PERIOD_M1.EURSEKmicro.csv',\n",
       " 'Xasmus.22236.PERIOD_M1.NZDUSDmicro.csv',\n",
       " 'Xasmus.17437.PERIOD_M1.EURUSDmicro.csv',\n",
       " 'Xasmus.18432.PERIOD_M1.GBPSEKmicro.csv',\n",
       " 'Xasmus.29106.PERIOD_M1.USDZARmicro.csv',\n",
       " 'Xasmus.13759.PERIOD_M1.USDDKKmicro.csv',\n",
       " 'Xasmus.4414.PERIOD_M1.AUDUSDmicro.csv',\n",
       " 'Xasmus.3736.PERIOD_M1.CHFSGDmicro.csv',\n",
       " 'Xasmus.16194.PERIOD_M1.USDCHFmicro.csv',\n",
       " 'Xasmus.2719.PERIOD_M1.EURCHFmicro.csv',\n",
       " 'Xasmus.15462.PERIOD_M1.GBPUSDmicro.csv',\n",
       " 'Xasmus.7281.PERIOD_M1.AUDNZDmicro.csv',\n",
       " 'Xasmus.4992.PERIOD_M1.EURTRYmicro.csv',\n",
       " 'Xasmus.2187.PERIOD_M1.GBPJPYmicro.csv',\n",
       " 'Xasmus.31992.PERIOD_M1.CHFJPYmicro.csv',\n",
       " 'Xasmus.28178.PERIOD_M1.USDPLNmicro.csv',\n",
       " 'Xasmus.14950.PERIOD_M1.USDJPYmicro.csv',\n",
       " 'Xasmus.9450.PERIOD_M1.NZDCHFmicro.csv',\n",
       " 'Xasmus.17484.PERIOD_M1.EURZARmicro.csv',\n",
       " 'Xasmus.24857.PERIOD_M1.GBPAUDmicro.csv',\n",
       " 'Xasmus.21915.PERIOD_M1.EURCADmicro.csv',\n",
       " 'Xasmus.3980.PERIOD_M1.EURJPYmicro.csv',\n",
       " 'Xasmus.20756.PERIOD_M1.USDSEKmicro.csv',\n",
       " 'Xasmus.20615.PERIOD_M1.USDNOKmicro.csv',\n",
       " 'Xasmus.17453.PERIOD_M1.EURHKDmicro.csv']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filescsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pfl/Ironhack/project_Searching_for_Arbitrage_Opportunities_in_the_FX_Market_on_the_paper/datasets_csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CURRENT_PATH = os.getcwd()\n",
    "os.chdir(PATH_TO_FILES)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrived to the conclusion that the times in the rows are not the same for each pair of currency, there is a part of data cleaning and wrangling in order to be coherent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Xasmus.17302.PERIOD_M1.EURNZDmicro.csv \tNumber of NaNs: 0 \t 1394991 \t 2015.01.02 08:06:00\n",
      "1  Xasmus.23925.PERIOD_M1.USDMXNmicro.csv \tNumber of NaNs: 0 \t 1374169 \t 2015.01.02 08:07:00\n",
      "2  Xasmus.25659.PERIOD_M1.AUDCADmicro.csv \tNumber of NaNs: 0 \t 1394461 \t 2015.01.02 08:06:00\n",
      "3  Xasmus.27030.PERIOD_M1.CADJPYmicro.csv \tNumber of NaNs: 0 \t 1394806 \t 2015.01.02 08:06:00\n"
     ]
    }
   ],
   "source": [
    "n_nans = []\n",
    "count = []\n",
    "first_datetime = []\n",
    "\n",
    "for file in range(4): #len(filescsv)\n",
    "    df = pd.read_csv(filescsv[file])\n",
    "    n_nans.append(df[\"Price\"].isna().sum())\n",
    "    count.append(df[\"time\"].count())\n",
    "    first_datetime.append(df[\"time\"][0])\n",
    "    print(f\"{file}  {filescsv[file]}\",\"\\t\"+\"Number of NaNs:\",n_nans[-1],\"\\t\",count[-1],\"\\t\",first_datetime[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=666666>Text</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#4c4c4c>Text</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>number_nans</th>\n",
       "      <th>number_rows</th>\n",
       "      <th>first_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Xasmus.17302.PERIOD_M1.EURNZDmicro.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>1394991</td>\n",
       "      <td>2015.01.02 08:06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Xasmus.23925.PERIOD_M1.USDMXNmicro.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>1374169</td>\n",
       "      <td>2015.01.02 08:07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Xasmus.25659.PERIOD_M1.AUDCADmicro.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>1394461</td>\n",
       "      <td>2015.01.02 08:06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Xasmus.27030.PERIOD_M1.CADJPYmicro.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>1394806</td>\n",
       "      <td>2015.01.02 08:06:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                file_name  number_nans  number_rows  \\\n",
       "0  Xasmus.17302.PERIOD_M1.EURNZDmicro.csv            0      1394991   \n",
       "1  Xasmus.23925.PERIOD_M1.USDMXNmicro.csv            0      1374169   \n",
       "2  Xasmus.25659.PERIOD_M1.AUDCADmicro.csv            0      1394461   \n",
       "3  Xasmus.27030.PERIOD_M1.CADJPYmicro.csv            0      1394806   \n",
       "\n",
       "        first_datetime  \n",
       "0  2015.01.02 08:06:00  \n",
       "1  2015.01.02 08:07:00  \n",
       "2  2015.01.02 08:06:00  \n",
       "3  2015.01.02 08:06:00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to try with less values write <filecsv[:#number]> or <filecsv> to write all the values\n",
    "files_info_df = pd.DataFrame({\"file_name\":filescsv[:4],\"number_nans\":n_nans,\"number_rows\":count,\"first_datetime\":first_datetime})\n",
    "files_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_rows = files_info_df[files_info_df[\"number_rows\"] == files_info_df[\"number_rows\"].min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_reference = reference_rows[\"file_name\"].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating csv file including all the pairs forex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(point_reference) #Here the number inside \"filescsv[???] is the first number appeared before.\"\n",
    "currency = {\"time\": df_raw[\"time\"], df_raw[\"Symbol()\"][0][:-5]: df_raw[\"Price\"]}\n",
    "currency_df = pd.DataFrame(currency)\n",
    "currency_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_filescsv = filescsv[:point_reference] + filescsv[(point_reference+1):] #here the same, the numbers can vary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(new_filescsv)):\n",
    "    print(f\"{i}: {new_filescsv[i]}\")\n",
    "    df_raw = pd.read_csv(new_filescsv[i])\n",
    "    df_raw.set_index(\"time\", drop=True, inplace=True)\n",
    "    df_raw = df_raw.reindex(currency_df[\"time\"])\n",
    "    name = df_raw[\"Symbol()\"].dropna()\n",
    "    df_raw.reset_index(inplace=True)\n",
    "    currency_df[name[name.index[0]][:-5]] = df_raw[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_df.to_csv(\"arbitrage_forex_48_pairs_currency_v2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading currency_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_FILES = \"/home/pfl/Ironhack/project_Searching_for_Arbitrage_Opportunities_in_the_FX_Market_on_the_paper/results_csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pfl/Ironhack/project_Searching_for_Arbitrage_Opportunities_in_the_FX_Market_on_the_paper/results_csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CURRENT_PATH = os.getcwd()\n",
    "os.chdir(PATH_TO_FILES)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_df = pd.read_csv(\"arbitrage_forex_48_pairs_currency_v2.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1365805"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currency_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "small_df = currency_df.iloc[0:365805]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connection with the database (MySQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "driver = 'mysql+pymysql:'\n",
    "user = 'root'\n",
    "password = '12345678'\n",
    "ip = '127.0.0.1'\n",
    "database = 'project_Arbitrage_Opportunities_FX_Market'\n",
    "\n",
    "connection_string = f'{driver}//{user}:{password}@{ip}/{database}'\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def update_progress(progress):\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################] 100.0%\n"
     ]
    }
   ],
   "source": [
    "number_of_elements = 1000\n",
    "\n",
    "for i in range(number_of_elements):\n",
    "    x = i*2\n",
    "    print(x)\n",
    "    #time.sleep(0.01) #Replace this with a real computation\n",
    "    update_progress(i / number_of_elements)\n",
    "print(x)\n",
    "update_progress(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 5\n",
    "count = 0\n",
    "for split in np.split(currency_df,a):\n",
    "    #print(count)\n",
    "    #print(split)\n",
    "    split.to_sql(f\"partial_{count}_pairs_of_currencies\",engine,if_exists = 'replace')\n",
    "    count+=1\n",
    "    time.sleep(15)\n",
    "    #update_progress(i / number_of_elements)\n",
    "#update_progress(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_df.to_sql(\"full_pairs_of_currencies\",engine,chunksize=150000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "            SELECT table_schema \"database\", sum(data_length + index_length)/1024/1024 \"size in MB\" FROM information_schema.TABLES WHERE table_schema='project_Arbitrage_Opportunities_FX_Market';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_used_database_pair_of_currencies = pd.read_sql(query,engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>database</th>\n",
       "      <th>size in MB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>project_Arbitrage_Opportunities_FX_Market</td>\n",
       "      <td>564.5625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    database  size in MB\n",
       "0  project_Arbitrage_Opportunities_FX_Market    564.5625"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space_used_database_pair_of_currencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Pairs Table (18 currencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_headers = currency_df.columns.tolist()\n",
    "list_headers = list_headers[1:]\n",
    "list_currencies = []\n",
    "for position in list_headers:\n",
    "    list_currencies.append(position[:3])\n",
    "    list_currencies.append(position[3:])\n",
    "set_currencies = set(list_currencies)\n",
    "unique_currencies = sorted(list(set_currencies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_table_df = pd.DataFrame(0, index=unique_currencies, columns=unique_currencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {currency: [0] for currency in unique_currencies}\n",
    "pairs_table_df = pd.DataFrame(data=d, index=unique_currencies)\n",
    "pairs_table_df = pairs_table_df.sort_index()\n",
    "pairs_table_df.columns = pairs_table_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def deleting_rows_columns_only_nans(df):\n",
    "    columns_to_remove = []\n",
    "    for column in df.columns:\n",
    "        dropping = df[column].drop(column)\n",
    "        if dropping.isna().all():\n",
    "            columns_to_remove.append(column)\n",
    "    df.drop(columns_to_remove, axis=1, inplace=True)\n",
    "    df.drop(columns_to_remove, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SAVING_PATH = \"/home/pau/Ironhack/week9/final_project/Project-Week-8-Final-Project/your-project/code/possibles_arbitrages_currencies\"\n",
    "\n",
    "for index in range(len(currency_df[\"time\"][0:])): #I wrote \"20\" in this case because I wanted to iterate only the first 20 tables, to iterate until the end I have to write \"[0:]\"\n",
    "    for row in pairs_table_df.columns:\n",
    "        for column in pairs_table_df.index:\n",
    "            try:\n",
    "                if row == column:\n",
    "                    pairs_table_df.loc[row,column] = 1\n",
    "                else:\n",
    "                    pairs_table_df.loc[row,column] = currency_df.loc[index][1:][row+column]\n",
    "                    pairs_table_df.loc[column,row] = 1/currency_df.loc[index][1:][row+column]    # perquè és \"df.iloc\" i no \"df.loc\" ????\n",
    "            except:\n",
    "                if pairs_table_df.loc[row,column] == 0:\n",
    "                    pairs_table_df.loc[row,column] = np.NaN\n",
    "    print(f\"{index}   Iteration {currency_df.time[index]}\")\n",
    "    pairs_table_df = deleting_rows_columns_only_nans(pairs_table_df)\n",
    "    pairs_table_df.to_csv(f\"{SAVING_PATH}/{currency_df.time[index]}_possible_arbitrage.csv\")\n",
    "    pairs_table_df = pd.DataFrame(0, index=unique_currencies, columns=unique_currencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbitrage opportunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_FILES = \"/home/pau/Ironhack/week9/final_project/Project-Week-8-Final-Project/your-project/code/possibles_arbitrages_currencies\"\n",
    "filescsv = os.listdir(PATH_TO_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_PATH = os.getcwd()\n",
    "os.chdir(PATH_TO_FILES)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bellman Ford Algorithm to find the arbitrage opportunity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(currencies):\n",
    "    G = nx.DiGraph()\n",
    "    for series in currencies:\n",
    "        G.add_nodes_from(series.index)\n",
    "        # \"\"\"series.index[i] = ROWS\"\"\" \"\"\"series.name = COLUMNS\"\"\"\n",
    "        G.add_edges_from([(series.index[i], series.name, {'weight':-np.log(series[i])}) for i in range(len(series))])\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_formatter(df):\n",
    "    series = []\n",
    "    for i in df.columns:\n",
    "        values = df[i].apply(lambda x: x if x !=1.0 else np.nan)\n",
    "        values = values.dropna()\n",
    "        series.append(values)\n",
    "    return series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculation_profit(clist):\n",
    "    total = 1\n",
    "    for i in range(1,len(clist)):\n",
    "        total *= arb_df.loc[clist[i-1]][clist[i]]\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_profit_results(results,unique_paths):\n",
    "    currencies_paths = results[1]\n",
    "    profit = calculation_profit(currencies_paths)\n",
    "    if (profit > 1.00005) and (currencies_paths not in unique_paths):\n",
    "        print(f\"Path: {currencies_paths}\")\n",
    "        for i in range(1,len(currencies_paths)):\n",
    "            print(f\"{currencies_paths[i-1]}-{currencies_paths[i]}\",arb_df.loc[currencies_paths[i-1]][currencies_paths[i]]) #arb_df.loc[ROWS][COLUMNS]\n",
    "        print(f\"Profit: {profit-1}\")\n",
    "        print(\"\\n\")\n",
    "        unique_paths.append(currencies_paths)\n",
    "    return unique_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "timestamp = []\n",
    "path_id = []\n",
    "complete_path = []\n",
    "source = []\n",
    "target = []\n",
    "change = []\n",
    "profit_lst = []\n",
    "\n",
    "path_counter = 0\n",
    "for file in range(len(filescsv)):\n",
    "#for file in range(0,8):\n",
    "    print(f\"{file}   ############################## {filescsv[file]} ##############################\")\n",
    "    arb_df = pd.read_csv(filescsv[file], index_col=0)\n",
    "    currencies = columns_formatter(arb_df)\n",
    "    G = create_graph(currencies)\n",
    "    unique_paths = []\n",
    "    for i in arb_df.index:\n",
    "        results = bf.bellman_ford(G, source=i, target=i, weight=\"weight\")\n",
    "        currencies_paths = results[1]\n",
    "        profit = calculation_profit(currencies_paths)\n",
    "        if (profit > 1.00005) and (currencies_paths not in unique_paths):\n",
    "            #print(f\"Path: {currencies_paths}\")\n",
    "            for j in range(1,len(currencies_paths)):\n",
    "                timestamp.append(filescsv[file])\n",
    "                source.append(currencies_paths[j-1])\n",
    "                target.append(currencies_paths[j])\n",
    "                change.append(arb_df.loc[currencies_paths[j-1]][currencies_paths[j]])\n",
    "                #print(f\"{source[-1]}-{target[-1]}\",change[-1]) #arb_df.loc[ROWS][COLUMNS]\n",
    "                path_id.append(path_counter)\n",
    "                complete_path.append(currencies_paths)\n",
    "                profit_lst.append(profit-1)\n",
    "            path_counter += 1\n",
    "            #print(f\"Profit: {profit-1}\")\n",
    "            #print(\"\\n\")\n",
    "            unique_paths.append(currencies_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame({\"timestamp\":timestamp,\"path_id\":path_id,\"complete_path\":complete_path,\"source\":source,\"target\":target,\"change\":change,\"profit\":profit_lst})\n",
    "print(len(timestamp))\n",
    "print(len(path_id))\n",
    "print(len(complete_path))\n",
    "print(len(source))\n",
    "print(len(target))\n",
    "print(len(change))\n",
    "print(len(profit_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
